

# ğŸ‘‹ Amman Hussain Ansari

### ğŸ§  Building AI Systems from Mathematical First Principles

[![Typing SVG](https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=600&size=22&pause=1000&color=00D9FF&center=true&vCenter=true&width=800&lines=ML+Engineer+%7C+Deep+Learning+%7C+NLP+%7C+LLMs;RAG+Systems+%7C+GenAI+%7C+MLOps+%7C+Cloud;Learning+in+Public+%7C+Building+from+Scratch)](https://git.io/typing-svg)

[![LinkedIn](https://img.shields.io/badge/LinkedIn-ammmanism-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ammmanism/)
[![Twitter](https://img.shields.io/badge/Twitter-ammmanism-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/ammmanism)
[![GitHub followers](https://img.shields.io/github/followers/ammmanism?style=for-the-badge&logo=github)](https://github.com/ammmanism)
![Profile Views](https://komarev.com/ghpvc/?username=ammmanism&color=blueviolet&style=for-the-badge)

</div>

---

## ğŸ§­ Core Philosophy

> **Mathematics â†’ Algorithms â†’ Models â†’ Systems â†’ Infrastructure**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mathematics â”‚  â† Calculus, Probability, Linear Algebra, Statistics
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Algorithms  â”‚  â† ML from scratch, optimization theory
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Models    â”‚  â† DL, Transformers, LLMs, RAG
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Systems   â”‚  â† Production pipelines, APIs, evaluation
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Infrastructureâ”‚ â† Docker, K8s, AWS, CI/CD, MLOps
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

If I can't explain WHY something works, I don't consider it learned.
```

I am building **AI systems from scratch** â€” no shortcuts, no black boxes. This GitHub is my **public research & engineering notebook**.

---

## ğŸ¯ What I'm Optimizing For

- ğŸ§  **Deep Conceptual Understanding** â€” Math â†’ Code
- ğŸ“ **Mathematical Clarity** â€” Derivations, proofs, intuition
- ğŸ—ï¸ **System-Level Thinking** â€” Scalable, production-ready
- ğŸ”¬ **Research Readiness** â€” PhD-track rigor
- ğŸš€ **Production Competence** â€” Docker, K8s, AWS, MLOps

---

## ğŸ“Š Live Skill Progress (Honest, Not Hype)

### ğŸ“ Mathematics Foundation
```
Calculus & Optimization       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 70%
Probability & Bayesian         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 65%
Statistics & Inference         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%
Linear Algebra (ML-focused)    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 65%
```

### ğŸ¤– Machine Learning
```
Supervised ML (from scratch)   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 75%
Unsupervised ML                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 65%
Biasâ€“Variance Theory           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%
Feature Engineering            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 65%
```

### ğŸ§¬ Deep Learning
```
Backpropagation Theory         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 65%
MLP / CNN Internals            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%
Optimizers & Regularization    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%
```

### ğŸ§  Transformers & LLMs
```
Attention Mechanisms           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
Transformer Blocks             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
LLM Training Concepts          â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
Fine-tuning & PEFT             â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
```

### ğŸ” RAG & GenAI
```
Document Processing            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
Retrieval Systems              â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
End-to-End RAG Pipelines       â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
Vector Databases               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
```

### ğŸ—ï¸ MLOps & Infrastructure
```
Docker & Containers            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%
CI/CD Pipelines                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
Kubernetes (K8s)               â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
AWS ML Workflows               â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
Terraform                      â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 30%
```

### ğŸ’» DSA & Optimization
```
Arrays, Strings, LinkedLists   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%
Trees & Graphs                 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 50%
Dynamic Programming            â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%
```

---

## ğŸ› ï¸ Tech Stack

<div align="center">

### Languages & Core Libraries
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)

### ML/DL Frameworks
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)

### GenAI & LLM Stack
![LangChain](https://img.shields.io/badge/LangChain-121212?style=for-the-badge&logo=chainlink&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![Pinecone](https://img.shields.io/badge/Pinecone-000000?style=for-the-badge)
![Weaviate](https://img.shields.io/badge/Weaviate-00C7B7?style=for-the-badge)

### Backend & APIs
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-000000?style=for-the-badge&logo=flask&logoColor=white)

### DevOps & Cloud
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)

### Databases
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)
![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=for-the-badge&logo=mongodb&logoColor=white)
![Redis](https://img.shields.io/badge/Redis-DC382D?style=for-the-badge&logo=redis&logoColor=white)

### Tools
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)
![VS Code](https://img.shields.io/badge/VS_Code-007ACC?style=for-the-badge&logo=visual-studio-code&logoColor=white)

</div>

---

## ğŸ“š Learning Resource Map (Structured Order)

<details>
<summary><b>ğŸ“ Mathematics Foundation (Click to expand)</b></summary>

### Calculus
- **3Blue1Brown â€“ Essence of Calculus** (12 videos, ~3 hours)
  - Visual intuition for gradients, chain rule, optimization

### Probability
- **3Blue1Brown â€“ Probability** (10 videos, ~3 hours)
  - Bayesian thinking, distributions

</details>

<details>
<summary><b>ğŸ“Š Statistics</b></summary>

- **Steve Brunton â€“ Data-Driven Science** (35 videos, ~8 hours)
  - Sampling, hypothesis testing, estimation theory

</details>

<details>
<summary><b>ğŸ¤– Machine Learning Core</b></summary>

- **Sebastian Raschka â€“ Machine Learning** (95 videos, ~40 hours)
  - Theory + implementation depth
  - Loss functions, optimization, regularization

</details>

<details>
<summary><b>ğŸ§¬ Deep Learning & Transformers</b></summary>

- Neural Networks from scratch
- Backpropagation derivations
- Attention mechanisms â†’ Transformer â†’ GPT/BERT

</details>

<details>
<summary><b>ğŸ­ GenAI Production</b></summary>

- **Andrew Brown â€“ GenAI Bootcamp** (66+ hours)
  - Production RAG systems
  - LLM deployment patterns

</details>

---

## ğŸ§± Repository Map (Learning in Public)

### âœ… **CURRENTLY ACTIVE / COMPLETED**

<table>
<tr>
<td width="50%">

#### ğŸ“Œ [ml-from-scratch](https://github.com/ammmanism/ml-from-scratch) âœ…

**Status:** ğŸŸ¢ Active Development

**What this proves:**
- ML algorithms from mathematical equations
- Pure NumPy implementations
- Loss derivations, gradient calculations
- Unit tests + visualizations
- Comparison with sklearn

**Algorithms:**
- âœ… Linear Regression
- âœ… Logistic Regression
- âœ… K-Nearest Neighbors
- âœ… K-Means Clustering
- ğŸš§ Naive Bayes
- ğŸš§ Decision Trees

```python
# Example: Linear Regression from scratch
âˆ‚L/âˆ‚w = (1/n)X^T(Xw - y)
w := w - Î±(âˆ‚L/âˆ‚w)
```

**Tech:** Python â€¢ NumPy â€¢ Matplotlib â€¢ pytest

â­ **Foundation of everything else**

</td>
<td width="50%">

#### ğŸš§ [probability-statistics-simulations](https://github.com/ammmanism/probability-statistics-simulations)

**Status:** ğŸŸ¡ Planned

**Focus:**
- Monte Carlo simulations
- Bayesian inference
- Hypothesis testing via code
- Statistical intuition through experiments

**Topics:**
- Distributions (Normal, Binomial, Poisson)
- Central Limit Theorem
- Confidence intervals
- Bootstrap methods

</td>
</tr>
</table>

### ğŸš§ **UPCOMING (PLANNED & STRUCTURED)**

<table>
<tr>
<td width="50%">

#### ğŸ”œ [deep-learning-from-scratch](https://github.com/ammmanism/deep-learning-from-scratch)

**Focus:**
- Backpropagation from first principles
- MLP & CNN architectures
- Layer implementations (Dense, Conv2D, BatchNorm)
- Optimizers (SGD, Momentum, Adam, RMSProp)

```python
# Backprop chain rule
âˆ‚L/âˆ‚x = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚x
```

</td>
<td width="50%">

#### ğŸ”œ [transformers-from-scratch](https://github.com/ammmanism/transformers-from-scratch)

**Focus:**
- Scaled dot-product attention
- Multi-head attention
- Positional encoding
- Transformer encoder/decoder
- GPT-style text generation

```python
Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V
```

</td>
</tr>

<tr>
<td width="50%">

#### ğŸ”œ [rag-from-scratch](https://github.com/ammmanism/rag-from-scratch)

**Focus:**
- Document ingestion & chunking
- Embedding strategies
- Dense vs sparse retrieval
- RAG evaluation (RAGAS metrics)
- Production pipeline

**Architecture:**
```
Documents â†’ Chunking â†’ Embedding â†’ Vector DB
                                      â†“
Query â†’ Embedding â†’ Retrieval â†’ LLM â†’ Response
```

</td>
<td width="50%">

#### ğŸ”œ [mlops-pipeline](https://github.com/ammmanism/mlops-pipeline)

**Focus:**
- Data pipeline design
- Training orchestration
- Model deployment (FastAPI)
- Monitoring & drift detection
- CI/CD with GitHub Actions

**Stack:** Docker, K8s, AWS, Terraform

</td>
</tr>

<tr>
<td width="50%">

#### ğŸ”œ [ensemble-methods-study](https://github.com/ammmanism/ensemble-methods-study)

**Focus:**
- Bagging vs Boosting
- Random Forests
- Gradient Boosting
- Stacking & Blending

</td>
<td width="50%">

#### ğŸ”œ [leetcode-solutions](https://github.com/ammmanism/leetcode-solutions)

**Focus:**
- DSA discipline for AI efficiency
- Arrays, Strings, Trees, Graphs, DP
- Clean categorized solutions

</td>
</tr>
</table>

---

## ğŸ§ª How I Build Projects

Every serious repo follows this architecture:

```
repo-name/
â”œâ”€â”€ README.md           â† What, Why, How
â”œâ”€â”€ src/                â† Clean modular code
â”œâ”€â”€ notebooks/          â† Intuition & experiments
â”œâ”€â”€ tests/              â† Unit tests for correctness
â”œâ”€â”€ docs/               â† Theory & explanation
â”œâ”€â”€ examples/           â† Real usage demos
â”œâ”€â”€ data/               â† Sample datasets
â””â”€â”€ requirements.txt    â† Dependencies
```

**Each README answers:**
1. â“ What problem?
2. ğŸ“ What math?
3. âš™ï¸ What algorithm?
4. ğŸ’¡ Why it works?
5. ğŸš€ How it scales?

---

## ğŸ“Š GitHub Activity

<div align="center">

![GitHub Streak](https://github-readme-streak-stats.herokuapp.com/?user=ammmanism&theme=tokyonight&hide_border=true&background=0D1117&stroke=0D1117&ring=58A6FF&fire=FF6B6B&currStreakLabel=58A6FF)

![Activity Graph](https://github-readme-activity-graph.vercel.app/graph?username=ammmanism&theme=tokyo-night&hide_border=true&bg_color=0D1117&color=58A6FF&line=FF6B6B&point=FFFFFF)

</div>

<div align="center">
<table>
<tr>
<td width="50%">

![Stats](https://github-readme-stats.vercel.app/api?username=ammmanism&show_icons=true&theme=tokyonight&hide_border=true&bg_color=0D1117&title_color=58A6FF&text_color=C9D1D9&icon_color=FF6B6B)

</td>
<td width="50%">

![Top Languages](https://github-readme-stats.vercel.app/api/top-langs/?username=ammmanism&layout=compact&theme=tokyonight&hide_border=true&bg_color=0D1117&title_color=58A6FF&text_color=C9D1D9)

</td>
</tr>
</table>
</div>

---

## ğŸ¯ Research-Oriented Approach

I treat each repository as:
- ğŸ“„ A **mini research paper**
- ğŸ§ª A **reproducible experiment**
- ğŸ§± A **building block for larger systems**

**Future direction:**
- Advanced Reinforcement Learning (PPO, DDPG, SAC)
- LLM fine-tuning (LoRA, QLoRA, PEFT)
- Distributed training
- Multi-modal models
- Research-grade experimentation

---

## ğŸ—ºï¸ 90-Day Execution Roadmap

<details>
<summary><b>Week 1-2: Mathematics & ML Foundation</b></summary>

- Complete `ml-from-scratch` (Linear, Logistic, KNN, K-Means)
- Add Naive Bayes & Decision Trees
- Full test coverage + visualizations

</details>

<details>
<summary><b>Week 3-4: Deep Learning Fundamentals</b></summary>

- Start `deep-learning-from-scratch`
- Implement backprop from scratch
- Build MLP & CNN

</details>

<details>
<summary><b>Week 5-6: Transformers & Attention</b></summary>

- Start `transformers-from-scratch`
- Implement attention mechanism
- Build GPT-style model

</details>

<details>
<summary><b>Week 7-8: RAG & GenAI</b></summary>

- Start `rag-from-scratch`
- End-to-end RAG pipeline
- RAGAS evaluation

</details>

<details>
<summary><b>Week 9-10: MLOps & Production</b></summary>

- Start `mlops-pipeline`
- Docker + K8s deployment
- CI/CD setup

</details>

<details>
<summary><b>Week 11-12: Portfolio & Kaggle</b></summary>

- Portfolio website
- First Kaggle competition
- Resume + blog posts

</details>

---

## ğŸ† Achievements & Milestones

```
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Kaggle Medal (Target: Q2 2025)
[â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] LeetCode 100 problems
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘] ml-from-scratch completion
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] First RAG production deploy
[â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] First open-source contribution
```

---

## ğŸ§­ Long-Term Vision

- ğŸ“ **Research-focused AI/ML** (PhD-track rigor)
- ğŸ§  **Strong mathematical grounding**
- ğŸ—ï¸ **Scalable GenAI systems** (production-ready)
- ğŸŒ **Global research & engineering roles**
- ğŸ“ **Publishing research papers**
- ğŸ¤ **Contributing to open-source AI**

---

## ğŸ“¬ Connect With Me

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ammmanism/)
[![Twitter](https://img.shields.io/badge/Twitter-Follow-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/ammmanism)
[![Email](https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:your.email@example.com)

</div>

---

<div align="center">

### ğŸ’­ Philosophy

```
"I don't just train models â€” I understand why they work.
 I don't just use tools â€” I build them from scratch.
 I don't just follow tutorials â€” I write the theory."
```

**Building slowly, deeply, and correctly â€” because foundations matter.**

---

![Visitor Count](https://visitor-badge.laobi.icu/badge?page_id=ammmanism.ammmanism&left_color=gray&right_color=blue&left_text=Profile%20Visitors)

â­ **If you find my work interesting, consider starring my repositories!** â­

</div>
